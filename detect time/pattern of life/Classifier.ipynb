{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append('../../../Mental_Disorder/3_feature_visualization') # get old tweets library\n",
    "import age_gender_predictor\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Regular User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLangRatio(cursor):\n",
    "    lang_ratios = {}\n",
    "    for tweet in cursor:\n",
    "        lang = 1 if tweet[\"lang\"] == \"en\" else 0\n",
    "        user_id = tweet[\"user\"][\"id\"]\n",
    "        if user_id in lang_ratios:\n",
    "            lang_ratios[user_id].append(lang)\n",
    "        else:\n",
    "            lang_ratios[user_id] = [lang]\n",
    "    for user_id, ratio in lang_ratios.items():\n",
    "        lang_ratios[user_id] = np.sum(ratio) / len(ratio)\n",
    "    return lang_ratios\n",
    "\n",
    "def getUsersTweets(dbName,collectionName, en_threshold=0.9):\n",
    "    cursor = MongoClient(\"localhost\", 27017)[dbName][collectionName].find()\n",
    "    lang_ratios = getLangRatio(cursor)\n",
    "\n",
    "    cursor = MongoClient(\"localhost\", 27017)[dbName][collectionName].find()\n",
    "    usersTweets = {}\n",
    "    for tweet in cursor:\n",
    "        userID = tweet[\"user\"][\"id\"]\n",
    "        if lang_ratios[userID] < en_threshold:\n",
    "            continue\n",
    "        #Processing emotions from Carlos' API\n",
    "        emotion =  tweet[\"emotion\"][\"groups\"][0][\"name\"]\n",
    "        if len(tweet[\"emotion\"][\"groups\"]) > 1:\n",
    "            emotion_2 = tweet[\"emotion\"][\"groups\"][1][\"name\"]\n",
    "            \n",
    "        ambiguous = True if tweet['emotion']['ambiguous'] == 'yes' else False\n",
    "       \n",
    "        if len(tweet[\"emotion\"][\"groups\"]) > 1:\n",
    "            emotion_2 = tweet[\"emotion\"][\"groups\"][1][\"name\"]    \n",
    "        else:\n",
    "            emotion_2 = None\n",
    "        if tweet[\"polarity\"] == \"positive\":\n",
    "            polarity = 1\n",
    "        elif tweet[\"polarity\"] == \"negative\":\n",
    "            polarity = -1\n",
    "        else:\n",
    "            polarity = 0\n",
    "\n",
    "        date = tweet[\"created_at\"]\n",
    "        \n",
    "        text = tweet['text']\n",
    "\n",
    "        if userID not in usersTweets:\n",
    "            usersTweets[userID] = {}\n",
    "        if date not in usersTweets[userID]:\n",
    "            usersTweets[userID][date] = {}\n",
    "            \n",
    "        usersTweets[userID][date]['text'] = text\n",
    "        usersTweets[userID][date]['polarity'] =  polarity\n",
    "        usersTweets[userID][date]['emotion'] =  emotion\n",
    "        usersTweets[userID][date]['emotion_2'] =  emotion_2\n",
    "        usersTweets[userID][date]['ambiguous'] =  ambiguous\n",
    "    return usersTweets\n",
    "\n",
    "def timeSeriesTransform(usersEmotions):\n",
    "    for userID in usersEmotions:\n",
    "        usersEmotions[userID] = pd.DataFrame.from_dict(usersEmotions[userID], orient='index').fillna(0)\n",
    "        usersEmotions[userID]['dt'] = np.zeros(usersEmotions[userID].shape[0],dtype=float)\n",
    "        usersEmotions[userID].loc[:-1,'dt'] = (usersEmotions[userID].index[1:].values - usersEmotions[userID].index[:-1].values).astype('timedelta64[s]') / np.timedelta64(60, 's')\n",
    "    return list(usersEmotions.values())\n",
    "\n",
    "def getHTTPRows(timeSeries):\n",
    "    count = 0\n",
    "    patterns = ['http://','https://']\n",
    "    conditions = timeSeries['text'].str.contains(patterns[0])\n",
    "    for pattern in patterns[1:]:\n",
    "        conditions = conditions | timeSeries['text'].str.contains(pattern)\n",
    "\n",
    "    return conditions.values\n",
    "\n",
    "def userFilter(group, spam_threshold=0.5,tweets_threshold=25, time_filter = False):    #Spam and inactive user filter\n",
    "#     to restrict date in latest 8 weeks\n",
    "    if time_filter == True:\n",
    "        temp_group=[]\n",
    "        for timeSeries in group:\n",
    "            eight_week_period = timeSeries.index[-1]- timedelta(weeks=8)\n",
    "            temp_group.append(timeSeries[timeSeries.index > eight_week_period])\n",
    "        group = temp_group\n",
    "            \n",
    "    new_group = []\n",
    "    for timeSeries in group:\n",
    "        http_rows = getHTTPRows(timeSeries)\n",
    "        average_http_count = np.sum(http_rows) / timeSeries.shape[0]\n",
    "        if (average_http_count < spam_threshold) and (timeSeries.shape[0] > tweets_threshold):\n",
    "            new_group.append(timeSeries)\n",
    "    return new_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regular_tweets =  getUsersTweets(\"eric\",\"regularUser_en_fixed_emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regular_timeSeries = timeSeriesTransform(regular_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regular_clean = userFilter(regular_timeSeries, time_filter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTweets():\n",
    "    # {username:{int(date):{[(datetime,content,sentiment),...]}}}\n",
    "    tweets_dict = defaultdict(lambda: defaultdict(lambda:[]))\n",
    "    with open('../organized/date_sentiment_tweets') as tweets:\n",
    "        for line in tweets.readlines():\n",
    "            username, date, datetime, content, sentiment = line.split('\\t')\n",
    "            tweets_dict[username][int(date)].append((datetime, content, sentiment))\n",
    "            break\n",
    "    return tweets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_not_in_range(user, ill_time_dict,date):\n",
    "    if date >= ill_time_dict[user] - timedelta(days=42) \\\n",
    "    and date <= ill_time_dict[user] + timedelta(days=14):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def TweetsFormating(tweets_dict, ill_time_dict,en_threshold=0.9):\n",
    "    usersTweets = {}\n",
    "    for user in tweets_dict:\n",
    "        if user not in ill_time_dict: continue\n",
    "        userID = user\n",
    "        emotion_dict = defaultdict( lambda : defaultdict(lambda : []))\n",
    "        \n",
    "        emotion_here = 1\n",
    "        try:\n",
    "            with open('../patient emotion/' + user) as emotion_data:\n",
    "                for line in emotion_data.readlines():\n",
    "                    username, date, content, emotion1, emotion2, ambigu = line.split('\\t')\n",
    "                    emotion_dict[username][int(date)].append((content, emotion1, emotion2, ambigu))\n",
    "        except:\n",
    "            emotion_here = 0\n",
    "        \n",
    "        for date_ in tweets_dict[user]:\n",
    "            \n",
    "            if date_not_in_range(user, ill_time_dict ,datetime.strptime(str(date_), \"%Y%m%d\")): continue\n",
    "                \n",
    "            for tweet_info in tweets_dict[user][date_]:\n",
    "                date, content, polarity = tweet_info\n",
    "   \n",
    "                date = datetime.strptime(str(date), \"%Y-%m-%d %H:%M:%S\")\n",
    "                text = content\n",
    "                \n",
    "                if userID not in usersTweets:\n",
    "                    usersTweets[userID] = {}\n",
    "                if date not in usersTweets[userID]:\n",
    "                    usersTweets[userID][date] = {}\n",
    "\n",
    "                usersTweets[userID][date]['text'] = text\n",
    "                usersTweets[userID][date]['polarity'] =  int(polarity.strip())\n",
    "\n",
    "                usersTweets[userID][date]['emotion'] =  None\n",
    "                usersTweets[userID][date]['emotion_2'] =  None\n",
    "                usersTweets[userID][date]['ambiguous'] =  True\n",
    "                \n",
    "                true_yes_dict = {'yes':True, 'no':False}\n",
    "                \n",
    "                if emotion_here != 0:\n",
    "                    for tweet_emotion_info in emotion_dict[user][date_]:\n",
    "                        str1 = text.split(' ')\n",
    "                        str2 = tweet_emotion_info[0].split(' ')\n",
    "                        if float(len(set(str1) & set(str2)))/len(str1) > 0.4:\n",
    "                            usersTweets[userID][date]['emotion'] =  tweet_emotion_info[1]\n",
    "                            usersTweets[userID][date]['emotion_2'] =  tweet_emotion_info[2]\n",
    "                            usersTweets[userID][date]['ambiguous'] =  true_yes_dict[tweet_emotion_info[3].strip()]\n",
    "\n",
    "    return usersTweets\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# {username:{int(date):{[(datetime,content,sentiment),...]}}}\n",
    "bd_dict = loadTweets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ill Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Counts from month ill time:277\n"
     ]
    }
   ],
   "source": [
    "def readPatientIllTime(folder, filename):\n",
    "    with open(folder + filename, 'r') as openfile:\n",
    "        return [line.strip().split('\\t') for line in openfile.readlines()]\n",
    "    \n",
    "# ## Get ill time information\n",
    "patient_ill_time_list = readPatientIllTime('../../twitter crawler/', 'bipolar_list')\n",
    "patient_ill_time_dict = {line[0]: line[1] for line in patient_ill_time_list}\n",
    "\n",
    "# dict[user][diagnosed_time(datetime)]\n",
    "patient_month_time_dict = {}\n",
    "\n",
    "for patient in patient_ill_time_dict:\n",
    "    datetime_list = patient_ill_time_dict[patient].split('/')\n",
    "    if len(datetime_list) > 1:\n",
    "        if len(datetime_list) > 2:\n",
    "            patient_month_time_dict[patient] = datetime(int(datetime_list[0]), int(datetime_list[1]), int(datetime_list[2]))\n",
    "        else:\n",
    "            patient_month_time_dict[patient] = datetime(int(datetime_list[0]),int(datetime_list[1]),1)\n",
    "    else:\n",
    "        continue\n",
    "print( 'Patient Counts from month ill time:' + str(len(patient_month_time_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bd_tweets = TweetsFormating(bd_dict, patient_month_time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd_timeSeries = timeSeriesTransform(bd_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd_clean = userFilter(bd_timeSeries, spam_threshold=0.8, tweets_threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = [ regular_clean, bd_clean]\n",
    "group_names = [\"Regular\", \"Bipolar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group      Users    Tweets    Average tweets\n",
      "-------  -------  --------  ----------------\n",
      "Regular      440     90848               206\n",
      "Bipolar      131    142596              1088\n"
     ]
    }
   ],
   "source": [
    "#Statistics facts of experimental data\n",
    "\n",
    "headers = [\"Group\",\"Users\", \"Tweets\", \"Average tweets\"]\n",
    "contents = []\n",
    "for i, group in enumerate(groups):\n",
    "    group_name = group_names[i]\n",
    "    tweets_num = sum([timeSeries.shape[0] for timeSeries in group])\n",
    "    users_num = len(group)\n",
    "    average_tweets_num = tweets_num / users_num\n",
    "    contents.append([group_name, users_num, tweets_num, average_tweets_num])\n",
    "    \n",
    "print(tabulate(contents, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Age and gender Distribution\n",
    "def getAgeGender(group):\n",
    "    features = {\"age\":[],\"gender\":[]}\n",
    "    for timeSeries in group:\n",
    "        \n",
    "        features[\"age\"].append(getAge(timeSeries))\n",
    "        features[\"gender\"].append(getGender(timeSeries))\n",
    "\n",
    "    return features\n",
    "def getAge(timeSeries):\n",
    "    texts = \"\"\n",
    "    for text in timeSeries[\"text\"].values:\n",
    "        texts += text + \"\\n\"\n",
    "    return age_gender_predictor.get_age(texts)\n",
    "\n",
    "def getGender(timeSeries):\n",
    "    texts = \"\"\n",
    "    for text in timeSeries[\"text\"].values:\n",
    "        texts += text + \"\\n\"\n",
    "    return age_gender_predictor.get_gender(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group      Male users    Female users    Average age\n",
      "-------  ------------  --------------  -------------\n",
      "Regular      0.488636        0.511364        29.4116\n",
      "Bipolar      0.274809        0.725191        25.4797\n"
     ]
    }
   ],
   "source": [
    "headers = [\"Group\",\"Male users\", \"Female users\", \"Average age\"]\n",
    "contents = []\n",
    "for i, group in enumerate(groups):\n",
    "    group_name = group_names[i]\n",
    "    users_num = float(len(group))\n",
    "    users_gender = [getGender(timeSeries) for timeSeries in group]\n",
    "    users_age = [getAge(timeSeries) for timeSeries in group]\n",
    "    male_ratio = len([gender for gender in users_gender if gender < 0]) / users_num\n",
    "    female_ratio = 1 - male_ratio\n",
    "    average_age = sum(users_age) / users_num\n",
    "    contents.append([group_name, male_ratio, female_ratio, average_age])\n",
    "print(tabulate(contents, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTweetRate(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    delta_time = np.max(timeSeries.index.values) - np.min(timeSeries.index.values)\n",
    "    total_duration = (delta_time).astype('timedelta64[h]') / np.timedelta64(24, 'h')\n",
    "#     if totla_duration == 0:\n",
    "#         totla_duration = 1\n",
    "    try:\n",
    "        result = total_tweets / float(total_duration)\n",
    "    except:\n",
    "        result = total_tweets / 1.0\n",
    "    return result\n",
    "\n",
    "def getMentionRate(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    total_mentions = np.sum(seriesContains(timeSeries))\n",
    "    return total_mentions / float(total_tweets)\n",
    "\n",
    "def thirdPronuonDetect(words, matcher=re.compile(\"@[a-z]+\")):\n",
    "    for word in words:\n",
    "        if word == \"@\":\n",
    "            continue\n",
    "        elif matcher.search(word):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def seriesContains(timeSeries):\n",
    "    match_function = np.vectorize(thirdPronuonDetect)\n",
    "    return match_function(timeSeries[\"text\"].str.lower().str.split().values)\n",
    "\n",
    "\n",
    "def getUniqueMentions(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    friends_set = set()\n",
    "    texts = timeSeries[\"text\"].values\n",
    "    for text in texts:\n",
    "        terms = text.strip().split()\n",
    "        for word in terms:\n",
    "            if word[0] == '@' and len(word) > 1:\n",
    "                friends_set.add(word)\n",
    "    return len(friends_set)\n",
    "\n",
    "def getFrequentMentions(timeSeries, lowerbound = 3):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    friends_mentions = {}\n",
    "    texts = timeSeries[\"text\"].values\n",
    "    for text in texts:\n",
    "        terms = text.strip().split()\n",
    "        for word in terms:\n",
    "            if word[0] == '@' and len(word) > 1:\n",
    "                friends_mentions[word] = friends_mentions.get(word, 0) +1\n",
    "    frequent_frients = [screen_name for screen_name, mentions in friends_mentions.items() if mentions >= lowerbound]\n",
    "    return len(frequent_frients)\n",
    " \n",
    "\n",
    "def getSocialFeature_group(group):\n",
    "    social_features = {\"tweets_rate\": [],\"mention_rate\": [],\"unique_mentions\": [],\"frequent_mentions\": []}\n",
    "    for timeSeries in group:\n",
    "        social_features[\"tweets_rate\"].append(getTweetRate(timeSeries))\n",
    "        social_features[\"mention_rate\"].append(getMentioRate(timeSeries))\n",
    "        social_features[\"unique_mentions\"].append(getUniqueMentions(timeSeries))\n",
    "        social_features[\"frequent_mentions\"].append(getFrequentMentions(timeSeries))\n",
    "    return social_features\n",
    "\n",
    "def getAllFeature(group, tail_k = \"all\"):\n",
    "    feature_set = {}\n",
    "    methods = [getSocialFeature_group, getGroupEmotions, getPolarity, getLIWC_group, getAgeGender]\n",
    "    for method in methods:\n",
    "        if method == getLIWC_group:\n",
    "            LIWC_feature_set = {\"LIWC_\"+key: value for key, value in method(group.getGroup(tail_k)).items()}\n",
    "            feature_set.update(LIWC_feature_set)\n",
    "        else:\n",
    "            feature_set.update(method(group.getGroup(tail_k)))\n",
    "    return feature_set\n",
    "\n",
    "def getSocialFeature_group(group):\n",
    "    social_features = {\"tweets_rate\": [],\"mention_rate\": [],\"unique_mentions\": [],\"frequent_mentions\": []}\n",
    "    for timeSeries in group:\n",
    "        social_features[\"tweets_rate\"].append(getTweetRate(timeSeries))\n",
    "        social_features[\"mention_rate\"].append(getMentioRate(timeSeries))\n",
    "        social_features[\"unique_mentions\"].append(getUniqueMentions(timeSeries))\n",
    "        social_features[\"frequent_mentions\"].append(getFrequentMentions(timeSeries))\n",
    "    return social_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Mean Distribution======\n",
      "\n",
      "           tweets_rate    mention_rate    unique_mentions    frequent_mentions\n",
      "-------  -------------  --------------  -----------------  -------------------\n",
      "Regular        4.38137        0.415265            37.6545                    5\n",
      "Bipolar       20.4919         0.388548           104.046                     7\n"
     ]
    }
   ],
   "source": [
    "header = [\"tweets_rate\", \"mention_rate\", \"unique_mentions\", \"frequent_mentions\"]\n",
    "contents = []\n",
    "for i, group in enumerate(groups):\n",
    "   \n",
    "    group_name = group_names[i]\n",
    "    content = [group_name]\n",
    "    tweets_rate = np.mean([getTweetRate(timeSeries) for timeSeries in group])\n",
    "    mention_rate = np.mean([getMentionRate(timeSeries) for timeSeries in group])\n",
    "    unique_mentions = np.mean([getUniqueMentions(timeSeries) for timeSeries in group])\n",
    "    frequent_mention = np.mean([getFrequentMentions(timeSeries) for timSeries in group])    \n",
    "    content += [tweets_rate, mention_rate, unique_mentions, frequent_mention]\n",
    "    contents.append(content)\n",
    "\n",
    "\n",
    "print(\"\\n======Mean Distribution======\\n\")\n",
    "\n",
    "print(tabulate(contents, headers=header,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFlipsCount(timeSeries, upperbound=60, lowerbound = 0):\n",
    "    flips = getFlips(timeSeries)\n",
    "    durations = getFlipsDuration(timeSeries, flips)\n",
    "    return np.sum((durations > lowerbound) & (durations < upperbound) )\n",
    "\n",
    "\n",
    "\n",
    "def getFlips(timeSeries, attribute= 'polarity'):\n",
    "    flips = np.zeros(timeSeries.shape[0],dtype=bool)\n",
    "    polarity = timeSeries[attribute].values[:-1]\n",
    "    right_elements = timeSeries[attribute].values[1:]\n",
    "    flips[:-1] = (polarity * right_elements) < 0\n",
    "    return flips\n",
    "\n",
    "\n",
    "def getFlipsDuration(timeSeries, flips):\n",
    "    filtered_timeSeries = timeSeries['dt'][flips].index.values\n",
    "    dt = np.zeros(filtered_timeSeries.shape[0],dtype=float)\n",
    "    dt[:-1] = (filtered_timeSeries[1:] - filtered_timeSeries[:-1]).astype('timedelta64[s]') / np.timedelta64(60, 's')\n",
    "    return dt\n",
    "\n",
    "def getCombosCount(timeSeries, matcher = -1, lowerbound = 2):\n",
    "    combos = comboTracker(timeSeries)\n",
    "    combos_count = sum([hit for element, hit in combos if element == matcher and hit > lowerbound])\n",
    "    return combos_count\n",
    "\n",
    "\n",
    "\n",
    "def getNegativeRatio(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    return np.sum(timeSeries[\"polarity\"].values == -1) / float(total_tweets)\n",
    "\n",
    "\n",
    "def getPositiveRatio(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    return np.sum(timeSeries[\"polarity\"].values == 1) / float(total_tweets)\n",
    "\n",
    "\n",
    "\n",
    "def getPolarity(group):\n",
    "    polarity = {\"flips\":[],\"negative_combos\":[],\"positive_combos\":[], \"positive_ratio\":[], \"negative_ratio\":[]}\n",
    "    for timeSeries in group:\n",
    "        try:\n",
    "            tweets_length = float(timeSeries.shape[0])\n",
    "        except:\n",
    "            print 'error'\n",
    "            print timeSeries\n",
    "            break\n",
    "        flips_ratio = getFlipsCount(timeSeries) / tweets_length\n",
    "        negative_combos_ratio = getCombosCount(timeSeries,matcher=-1) / tweets_length\n",
    "        positive_combos_ratio = getCombosCount(timeSeries,matcher=1) / tweets_length\n",
    "        positive_ratio = getPositiveRatio(timeSeries)\n",
    "        negative_ratio = getNegativeRatio(timeSeries)\n",
    "        \n",
    "        polarity[\"flips\"].append(flips_ratio)\n",
    "        polarity[\"negative_combos\"].append(negative_combos_ratio)\n",
    "        polarity[\"positive_combos\"].append(positive_combos_ratio)\n",
    "        polarity[\"positive_ratio\"].append(positive_ratio)\n",
    "        polarity[\"negative_ratio\"].append(negative_ratio)\n",
    "        \n",
    "    return polarity\n",
    "\n",
    "def comboTracker(timeSeries, attribute= \"polarity\", lowerbound = 120):\n",
    "    array = timeSeries[attribute]\n",
    "#     the polarity of starter\n",
    "    starter = array[0]\n",
    "    combo = 1\n",
    "    result = []\n",
    "    i = 0 \n",
    "#     begin from second one in the array\n",
    "    for cursor in array[1:]:\n",
    "        i += 1\n",
    "        if starter == cursor and timeSeries[\"dt\"][i-1] < lowerbound:\n",
    "            combo += 1\n",
    "        else:\n",
    "            if combo > 1:\n",
    "                result.append((starter, combo))\n",
    "            starter = cursor\n",
    "            combo = 1\n",
    "    if combo > 1:\n",
    "         result.append((starter, combo))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========\n",
      "\n",
      "Group      Positive Ratio Mean    Positive Ratio STD    Negative Ratio Mean    Negative Ratio STD\n",
      "-------  ---------------------  --------------------  ---------------------  --------------------\n",
      "Regular              0.222551              0.159819                0.107713             0.0804655\n",
      "Bipolar              0.0924273             0.0665547               0.177112             0.0831466\n"
     ]
    }
   ],
   "source": [
    "headers = [\"Group\",\"Positive Ratio Mean\",\"Positive Ratio STD\", \"Negative Ratio Mean\", \"Negative Ratio STD\"]\n",
    "contents = []\n",
    "for i, group in enumerate(groups):\n",
    "    group_name = group_names[i]\n",
    "   \n",
    "    positive_ratios = [getPositiveRatio(timeSeries) for timeSeries in group]\n",
    "    negative_ratios = [getNegativeRatio(timeSeries) for timeSeries in group]\n",
    "    positive_ratio_mean = np.mean(positive_ratios)\n",
    "    negative_ratio_mean = np.mean(negative_ratios)\n",
    "    positive_ratio_std = np.std(positive_ratios)\n",
    "    negative_ratio_std = np.std(negative_ratios)\n",
    "\n",
    "    contents.append([group_name, positive_ratio_mean, positive_ratio_std, negative_ratio_mean, negative_ratio_std])\n",
    "print(\"\\n=========\\n\")\n",
    "print(tabulate(contents, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_not_in_range(user, date):\n",
    "    if date >= patient_month_time_dict[user] - timedelta(days=42) \\\n",
    "    and date <= patient_month_time_dict[user] + timedelta(days=14):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def getUsersEmotionsDict(users_timeSeries):\n",
    "#     user -> emotion count\n",
    "    user_emotion_dict = defaultdict(lambda: {\"joy\":0,\n",
    "                                       \"sadness\": 0,\n",
    "                                       \"fear\":0,\n",
    "                                       \"anticipation\": 0,\n",
    "                                       \"anger\":0,\n",
    "                                       \"trust\": 0,\n",
    "                                       \"disgust\": 0,\n",
    "                                       \"surprise\" : 0\n",
    "                                      })\n",
    "    for user in users_timeSeries:\n",
    "        user_tweets_count = 0\n",
    "#         date, [tweet_info, tweets_info ...]\n",
    "        for date, tweets_infos in users_timeSeries[user].iteritems():\n",
    "            if date_not_in_range(user, datetime.strptime(str(date), \"%Y%m%d\")): continue\n",
    "            for tweet_info in tweets_infos:                \n",
    "    #             content, emotion1, emotion2, ambiguous\n",
    "                if(tweet_info[3].strip() != 'yes'):\n",
    "    #         only get the first emotion now\n",
    "                    user_emotion_dict[user][tweet_info[1]] += 1\n",
    "                    user_tweets_count += 1\n",
    "    \n",
    "        for emotion in user_emotion_dict[user]:\n",
    "            if user_tweets_count == 0:\n",
    "                user_emotion_dict[user][emotion] = 0\n",
    "            else:\n",
    "                user_emotion_dict[user][emotion] = float(user_emotion_dict[user][emotion]) / user_tweets_count\n",
    "    return user_emotion_dict\n",
    "\n",
    "def getUsersEmotions(timeSeries):\n",
    "    non_ambiguous = np.invert(timeSeries[\"ambiguous\"].values)\n",
    "    \n",
    "    filtered_emotions = timeSeries[\"emotion\"][non_ambiguous].values\n",
    "    emotions_count = {\"joy\":0,\"sadness\": 0,\"fear\":0,\\\n",
    "                \"anticipation\": 0, \"anger\":0, \"trust\": 0, \"disgust\": 0 ,\"surprise\" : 0}\n",
    "    if float(filtered_emotions.shape[0]) == 0:\n",
    "        divider = 1.0\n",
    "    else:\n",
    "        divider = float(filtered_emotions.shape[0])\n",
    "    for emotion in emotions_count:\n",
    "        emotions_count[emotion] = np.sum(filtered_emotions == emotion) / divider\n",
    "    return emotions_count\n",
    "\n",
    "def getGroupEmotions(group):\n",
    "    emotions_counts = {\"joy\":[],\"sadness\": [],\"fear\":[],\\\n",
    "                \"anticipation\": [], \"anger\":[], \"trust\": [], \"disgust\": [] ,\"surprise\" : []}\n",
    "    for timeSeries in group:\n",
    "        emotions_count = getUsersEmotions(timeSeries)\n",
    "        for emotion, count in emotions_count.items():\n",
    "            emotions_counts[emotion].append(count)\n",
    "    return emotions_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Eight Emotional Features======\n",
      "\n",
      "\n",
      "======Distribution======\n",
      "\n",
      "Group    joy     sadness    fear    anticipation    anger    trust    disgust    surprise\n",
      "-------  ------  ---------  ------  --------------  -------  -------  ---------  ----------\n",
      "Regular  16.03%  26.87%     6.53%   14.41%          6.98%    14.56%   11.4%      3.22%\n",
      "Bipolar  13.63%  28.25%     4.15%   14.6%           11.32%   6.55%    16.72%     4.79%\n"
     ]
    }
   ],
   "source": [
    "emotions = [\"joy\",\"sadness\",\"fear\", \"anticipation\", \"anger\", \"trust\", \"disgust\" ,\"surprise\"]\n",
    "\n",
    "headers = [\"Group\"] + emotions\n",
    "contents = []\n",
    "for i, group in enumerate(groups):\n",
    "   \n",
    "    group_name = group_names[i]\n",
    "    content = [group_name]\n",
    "    emotions_counts = getGroupEmotions(group)\n",
    "    for emotion in emotions:\n",
    "        emotion_ratio = \"{}%\".format(round(np.mean(emotions_counts[emotion])*100, 2))\n",
    "        \n",
    "        content.append(emotion_ratio)\n",
    "    contents.append(content)\n",
    "    \n",
    "print(\"\\n======Eight Emotional Features======\\n\")\n",
    "\n",
    "print(\"\\n======Distribution======\\n\")\n",
    "\n",
    "print(tabulate(contents, headers=headers,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
