{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append('../../../Mental_Disorder/3_feature_visualization') # get old tweets library\n",
    "import age_gender_predictor\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLangRatio(cursor):\n",
    "    lang_ratios = {}\n",
    "    for tweet in cursor:\n",
    "        lang = 1 if tweet[\"lang\"] == \"en\" else 0\n",
    "        user_id = tweet[\"user\"][\"id\"]\n",
    "        if user_id in lang_ratios:\n",
    "            lang_ratios[user_id].append(lang)\n",
    "        else:\n",
    "            lang_ratios[user_id] = [lang]\n",
    "    for user_id, ratio in lang_ratios.items():\n",
    "        lang_ratios[user_id] = np.sum(ratio) / len(ratio)\n",
    "    return lang_ratios\n",
    "\n",
    "def getUsersTweets(dbName,collectionName, en_threshold=0.9):\n",
    "    cursor = MongoClient(\"localhost\", 27017)[dbName][collectionName].find()\n",
    "    lang_ratios = getLangRatio(cursor)\n",
    "\n",
    "    cursor = MongoClient(\"localhost\", 27017)[dbName][collectionName].find()\n",
    "    usersTweets = {}\n",
    "    for tweet in cursor:\n",
    "        userID = tweet[\"user\"][\"id\"]\n",
    "        if lang_ratios[userID] < en_threshold:\n",
    "            continue\n",
    "        #Processing emotions from Carlos' API\n",
    "        emotion =  tweet[\"emotion\"][\"groups\"][0][\"name\"]\n",
    "        if len(tweet[\"emotion\"][\"groups\"]) > 1:\n",
    "            emotion_2 = tweet[\"emotion\"][\"groups\"][1][\"name\"]\n",
    "            \n",
    "        ambiguous = True if tweet['emotion']['ambiguous'] == 'yes' else False\n",
    "       \n",
    "        if len(tweet[\"emotion\"][\"groups\"]) > 1:\n",
    "            emotion_2 = tweet[\"emotion\"][\"groups\"][1][\"name\"]    \n",
    "        else:\n",
    "            emotion_2 = None\n",
    "        if tweet[\"polarity\"] == \"positive\":\n",
    "            polarity = 1\n",
    "        elif tweet[\"polarity\"] == \"negative\":\n",
    "            polarity = -1\n",
    "        else:\n",
    "            polarity = 0\n",
    "   \n",
    "            \n",
    "        date = tweet[\"created_at\"]\n",
    "        text = tweet['text']\n",
    "\n",
    "        if userID not in usersTweets:\n",
    "            usersTweets[userID] = {}\n",
    "        if date not in usersTweets[userID]:\n",
    "            usersTweets[userID][date] = {}\n",
    "            \n",
    "        usersTweets[userID][date]['text'] = text\n",
    "        usersTweets[userID][date]['polarity'] =  polarity\n",
    "        usersTweets[userID][date]['emotion'] =  emotion\n",
    "        usersTweets[userID][date]['emotion_2'] =  emotion_2\n",
    "        usersTweets[userID][date]['ambiguous'] =  ambiguous\n",
    "    return usersTweets\n",
    "\n",
    "def timeSeriesTransform(usersEmotions):\n",
    "    for userID in usersEmotions:\n",
    "        usersEmotions[userID] = pd.DataFrame.from_dict(usersEmotions[userID], orient='index').fillna(0)\n",
    "        usersEmotions[userID]['dt'] = np.zeros(usersEmotions[userID].shape[0],dtype=float)\n",
    "        usersEmotions[userID].loc[:-1,'dt'] = (usersEmotions[userID].index[1:].values - usersEmotions[userID].index[:-1].values).astype('timedelta64[s]') / np.timedelta64(60, 's')\n",
    "    return list(usersEmotions.values())\n",
    "\n",
    "def getHTTPRows(timeSeries):\n",
    "    count = 0\n",
    "    patterns = ['http://','https://']\n",
    "    conditions = timeSeries['text'].str.contains(patterns[0])\n",
    "    for pattern in patterns[1:]:\n",
    "        conditions = conditions | timeSeries['text'].str.contains(pattern)\n",
    "\n",
    "    return conditions.values\n",
    "\n",
    "def userFilter(group, spam_threshold=0.5,tweets_threshold=100, time_filter = False):    #Spam and inactive user filter\n",
    "#     to restrict date in latest 8 weeks\n",
    "    if time_filter == True:\n",
    "        temp_group=[]\n",
    "        for timeSeries in group:\n",
    "            eight_week_period = timeSeries.index[-1]- timedelta(weeks=8)\n",
    "            temp_group.append(timeSeries[timeSeries.index > eight_week_period])\n",
    "        group = temp_group\n",
    "            \n",
    "    new_group = []\n",
    "    for timeSeries in group:\n",
    "        http_rows = getHTTPRows(timeSeries)\n",
    "        average_http_count = np.sum(http_rows) / timeSeries.shape[0]\n",
    "        if (average_http_count < spam_threshold) and (timeSeries.shape[0] > tweets_threshold):\n",
    "            new_group.append(timeSeries)\n",
    "    return new_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regular_tweets =  getUsersTweets(\"eric\",\"regularUser_en_fixed_emotion\")\n",
    "regular_timeSeries = timeSeriesTransform(regular_tweets)\n",
    "regular_clean = userFilter(regular_timeSeries, time_filter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bipolar User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTweets():\n",
    "    # {username:{int(date):{[(datetime,content,sentiment),...]}}}\n",
    "    tweets_dict = defaultdict(lambda: defaultdict(lambda:[]))\n",
    "    with open('../organized/date_sentiment_tweets') as tweets:\n",
    "        for line in tweets.readlines():\n",
    "            username, date, datetime, content, sentiment = line.split('\\t')\n",
    "            tweets_dict[username][int(date)].append((datetime, content, sentiment))\n",
    "\n",
    "    return tweets_dict\n",
    "\n",
    "def TweetsFormating(tweets_dict, en_threshold=0.9):\n",
    "    usersTweets = {}\n",
    "    for user in tweets_dict:\n",
    "        userID = user\n",
    "        for date in tweets_dict[user]:\n",
    "            for tweet_info in tweets_dict[user][date]:\n",
    "                date, content, polarity = tweet_info\n",
    "   \n",
    "            \n",
    "#         date = tweet[\"created_at\"]\n",
    "                date = datetime.strptime(str(date), \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                text = content\n",
    "\n",
    "                if userID not in usersTweets:\n",
    "                    usersTweets[userID] = {}\n",
    "                if date not in usersTweets[userID]:\n",
    "                    usersTweets[userID][date] = {}\n",
    "\n",
    "                usersTweets[userID][date]['text'] = text\n",
    "                usersTweets[userID][date]['polarity'] =  int(polarity.strip())\n",
    "                usersTweets[userID][date]['emotion'] =  None\n",
    "                usersTweets[userID][date]['emotion_2'] =  None\n",
    "                usersTweets[userID][date]['ambiguous'] =  True\n",
    "    return usersTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {username:{int(date):{[(datetime,content,sentiment),...]}}}\n",
    "bd_tweets_dict = loadTweets()\n",
    "bd_tweets = TweetsFormating(bd_tweets_dict)\n",
    "bd_timeSeries = timeSeriesTransform(bd_tweets)\n",
    "bd_clean = userFilter(bd_timeSeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Tweet Frequence (All & Late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTweetRate(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    delta_time = np.max(timeSeries.index.values) - np.min(timeSeries.index.values)\n",
    "    totla_duration = (delta_time).astype('timedelta64[h]') / np.timedelta64(24, 'h')\n",
    "    return total_tweets / float(totla_duration)\n",
    "\n",
    "\n",
    "\n",
    "def thirdPronuonDetect(words, matcher=re.compile(\"@[a-z]+\")):\n",
    "    for word in words:\n",
    "        if word == \"@\":\n",
    "            continue\n",
    "        elif matcher.search(word):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def seriesContains(timeSeries):\n",
    "    match_function = np.vectorize(thirdPronuonDetect)\n",
    "    return match_function(timeSeries[\"text\"].str.lower().str.split().values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mention Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMentioRate(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    total_mentions = np.sum(seriesContains(timeSeries))\n",
    "    return total_mentions / float(total_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFrequentMentions(timeSeries, lowerbound = 3):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    friends_mentions = {}\n",
    "    texts = timeSeries[\"text\"].values\n",
    "    for text in texts:\n",
    "        terms = text.strip().split()\n",
    "        for word in terms:\n",
    "            if word[0] == '@' and len(word) > 1:\n",
    "                friends_mentions[word] = friends_mentions.get(word, 0) +1\n",
    "    frequent_frients = [screen_name for screen_name, mentions in friends_mentions.items() if mentions >= lowerbound]\n",
    "    return len(frequent_frients)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def getUniqueMentions(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    friends_set = set()\n",
    "    texts = timeSeries[\"text\"].values\n",
    "    for text in texts:\n",
    "        terms = text.strip().split()\n",
    "        for word in terms:\n",
    "            if word[0] == '@' and len(word) > 1:\n",
    "                friends_set.add(word)\n",
    "    return len(friends_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSocialFeature_group(group):\n",
    "    social_features = {\"tweets_rate\": [],\"mention_rate\": [],\"unique_mentions\": [],\"frequent_mentions\": []}\n",
    "    for timeSeries in group:\n",
    "        social_features[\"tweets_rate\"].append(getTweetRate(timeSeries))\n",
    "        social_features[\"mention_rate\"].append(getMentioRate(timeSeries))\n",
    "        social_features[\"unique_mentions\"].append(getUniqueMentions(timeSeries))\n",
    "        social_features[\"frequent_mentions\"].append(getFrequentMentions(timeSeries))\n",
    "    return social_features\n",
    "\n",
    "def summaryTable(groups,names, method, style=\"default\", tablefmt = \"simple\"):\n",
    "    header = [\"category\"]\n",
    "    group_counts = []\n",
    "    base = method(groups[0])\n",
    "    base_labels = [0] * len(groups[0])\n",
    "    contents = []\n",
    "    for name in names:\n",
    "        header.append(name + \" C\")\n",
    "        header.append(name + \" P\")\n",
    "        \n",
    "        \n",
    "    for group in groups:\n",
    "        group_counts.append(method(group))\n",
    "        \n",
    "        \n",
    "        \n",
    "    if style == \"default\":\n",
    "        for category, base_count in base.items():\n",
    "            content = [category]\n",
    "            for g,group in enumerate(groups):\n",
    "\n",
    "                labels = base_labels + ([1]*len(group))\n",
    "                counts = base_count + group_counts[g][category]\n",
    "                c, p = spearmanr(labels, counts)\n",
    "\n",
    "                content.append(c)\n",
    "                content.append(p)\n",
    "\n",
    "            contents.append(content)\n",
    "  \n",
    "        contents = sorted(contents, key=lambda pair: abs(pair[1]), reverse=True)           \n",
    "#        \n",
    "        print(tabulate(contents, headers=header,floatfmt=\".2f\", tablefmt=tablefmt))\n",
    "    \n",
    "    return contents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = [ regular_clean, bd_clean]\n",
    "group_names = [\"Regular\", \"Bipolar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Social Features======\n",
      "\n",
      "\n",
      "======Mean Distribution======\n",
      "\n",
      "           tweets_rate    mention_rate    unique_mentions    frequent_mentions\n",
      "-------  -------------  --------------  -----------------  -------------------\n",
      "Regular        3.39794        0.428638            171.801                   14\n",
      "Bipolar       13.4388         0.410792           1249.87                   248\n",
      "\n",
      "======Correlation======\n",
      "\n",
      "category             Regular C    Regular P    Bipolar C    Bipolar P\n",
      "-----------------  -----------  -----------  -----------  -----------\n",
      "mention_rate              0.00         1.00        -0.02         0.58\n",
      "tweets_rate               0.00         1.00         0.39         0.00\n",
      "frequent_mentions         0.00         1.00         0.45         0.00\n",
      "unique_mentions           0.00         1.00         0.46         0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['mention_rate', 0.0, 1.0, -0.019033248434176153, 0.58330919427396521],\n",
       " ['tweets_rate', 0.0, 1.0, 0.38650308886553408, 4.5299133213256252e-31],\n",
       " ['frequent_mentions', 0.0, 1.0, 0.45455536064650964, 1.0393704974252236e-43],\n",
       " ['unique_mentions', 0.0, 1.0, 0.45595333329949439, 5.3175753971622844e-44]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = [\"tweets_rate\", \"mention_rate\", \"unique_mentions\", \"frequent_mentions\"]\n",
    "contents = []\n",
    "for i, group in enumerate(groups):\n",
    "   \n",
    "    group_name = group_names[i]\n",
    "    content = [group_name]\n",
    "    tweets_rate = np.mean([getTweetRate(timeSeries) for timeSeries in group])\n",
    "    mention_rate = np.mean([getMentioRate(timeSeries) for timeSeries in group])\n",
    "    unique_mentions = np.mean([getUniqueMentions(timeSeries) for timeSeries in group])\n",
    "    frequent_mention = np.mean([getFrequentMentions(timeSeries) for timSeries in group])    \n",
    "    content += [tweets_rate, mention_rate, unique_mentions, frequent_mention]\n",
    "    contents.append(content)\n",
    "print(\"\\n======Social Features======\\n\")\n",
    "\n",
    "\n",
    "print(\"\\n======Mean Distribution======\\n\")\n",
    "\n",
    "print(tabulate(contents, headers=header,))\n",
    "print(\"\\n======Correlation======\\n\")\n",
    "summaryTable(groups,group_names,getSocialFeature_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Tweets Rate    Mention Rate    Unique Mentions    Frequent Mentions\n",
      "---  -------------  --------------  -----------------  -------------------\n",
      "  0       6.81164       0.2595                    238                  117\n",
      "  1       7.0263        0.212496                  702                  161\n",
      "  2       2.53227       0.323556                  299                  135\n",
      "  3       1.46817       0.389901                   45                   15\n",
      "  4      14.1067        0.839319                  529                  223\n",
      "  5      22.4799        0.244232                  216                   20\n",
      "  6       4.89036       0.263087                  357                  134\n",
      "  7      19.396         0.228978                 1073                  455\n",
      "  8       5.27919       0.390708                  597                  227\n",
      "  9      11.039         0.759985                23868                 2727\n",
      " 10      34.8176        0.490107                 4375                 1237\n",
      " 11       2.15782       0.146186                   75                   23\n",
      " 12      31.2189        0.380057                 1262                  416\n",
      " 13      37.8683        0.386002                 2775                  980\n",
      " 14      27.8893        0.28848                  1405                  573\n",
      " 15       0.99131       0.915446                  309                  127\n",
      " 16       0.102153      0.0533333                  13                    0\n",
      " 17       2.39456       0.408168                  298                   78\n",
      " 18      10.2478        0.374461                  321                  141\n",
      " 19      34.9477        0.565481                 6040                 1969\n",
      " 20       2.77615       0.278187                  465                  134\n",
      " 21      23.3119        0.727813                 1333                  441\n",
      " 22       3.131         0.417855                  294                   86\n",
      " 23       7.28552       0.206634                  659                  206\n",
      " 24       0.55553       0.873632                  231                   52\n",
      " 25       2.15009       0.0399202                 116                   12\n",
      " 26       4.71406       0.415572                  303                  129\n",
      " 27      11.9842        0.261032                  269                  113\n",
      " 28       8.8441        0.785692                 1144                  433\n",
      " 29      17.7298        0.389523                 1630                  624\n",
      " 30       0.78551       0.355022                  163                   50\n",
      " 31       8.37487       0.744504                 1196                  411\n",
      " 32     262.21          0.00019433                 36                    1\n",
      " 33      28.1184        0.140603                 1897                  391\n",
      " 34      40.3723        0.29675                  1600                  484\n",
      " 35       5.98941       0.467255                  917                  252\n",
      " 36      28.5309        0.371296                 2293                 1016\n",
      " 37      18.0409        0.423765                 1337                  684\n",
      " 38       2.69336       0.490921                 1040                  307\n",
      " 39       4.46907       0.105536                   32                   12\n",
      " 40       7.62199       0.290106                  463                  117\n",
      " 41       3.73529       0.430252                  298                  114\n",
      " 42       3.36462       0.216999                  303                   65\n",
      " 43       8.0702        0.535621                 1831                  524\n",
      " 44      10.8375        0.295582                  978                  375\n",
      " 45       5.18418       0.199942                  151                   56\n",
      " 46       1.50369       0.399269                  267                   88\n",
      " 47       1.4065        0.208481                   49                    8\n",
      " 48       0.728121      0.770362                  433                   77\n",
      " 49      13.9418        0.416635                 1590                  619\n",
      " 50       3.4653        0.138117                   92                   35\n",
      " 51      32.8548        0.986478                  906                  465\n",
      " 52       0.284296      0.727397                  260                   46\n",
      " 53      13.5118        0.860568                 1299                  510\n",
      " 54       1.393         0.0153999                  30                    3\n",
      " 55       3.62992       0.0993103                 146                   57\n",
      " 56       3.56036       0.761242                  525                  101\n",
      " 57       1.87087       0.34546                   388                  137\n",
      " 58       7.1191        0.416667                  197                   24\n",
      " 59      78.8897        0.58193                  2390                 1272\n",
      " 60       1.26103       0.388194                  163                   54\n",
      " 61       0.134785      0.657459                   55                   10\n",
      " 62      15.5864        0.480667                 1053                  272\n",
      " 63       2.29033       0.331471                  245                   84\n",
      " 64      10.1444        0.281589                  109                   49\n",
      " 65       0.143333      0.940426                  107                   15\n",
      " 66      10.6144        0.658126                 1765                  590\n",
      " 67       2.00601       0.508083                  422                  120\n",
      " 68       1.82144       0.564216                  754                  241\n",
      " 69      24.6016        0.74117                  2388                 1051\n",
      " 70       2.28319       0.405165                  326                  116\n",
      " 71       6.13102       0.329251                 1844                  419\n",
      " 72       5.2009        0.563133                 1637                  360\n",
      " 73      27.9506        0.609269                 1170                  483\n",
      " 74       2.85249       0.645874                  757                  241\n",
      " 75      15.0334        0.480842                  929                  331\n",
      " 76      31.4058        0.545644                 2121                  924\n",
      " 77       0.780174      0.15099                    46                    6\n",
      " 78      39.677         0.644307                 1969                  989\n",
      " 79       2.75478       0.00409776                  9                    1\n",
      " 80      12.9032        0.429345                 1235                  513\n",
      " 81       1.3556        0.191453                   46                   16\n",
      " 82       0.478073      0.227006                   55                   12\n",
      " 83      15.184         0.404263                 1218                  415\n",
      " 84      14.5774        0.389166                 1612                  359\n",
      " 85      19.8251        0.222322                 2044                  565\n",
      " 86       1.83103       0.590736                  904                  243\n",
      " 87      20.9804        0.504605                 5054                 1111\n",
      " 88      21.2849        0.203918                  150                   41\n",
      " 89       6.00386       0.352912                  776                  339\n",
      " 90      36.3649        0.446011                 5395                 1842\n",
      " 91      16.7015        0.741799                 2346                  856\n",
      " 92      48.6542        0.446625                 3886                 1423\n",
      " 93      10.4443        0.177546                  596                  198\n",
      " 94      18.0605        0.479354                 1148                  392\n",
      " 95       3.42378       0.325171                  148                   29\n",
      " 96       5.23567       0.252346                  146                   48\n",
      " 97      36.2942        0.179251                 4509                 1074\n",
      " 98       4.60384       0.663557                  510                  153\n",
      " 99       1.16184       0.426794                  313                  104\n",
      "100      15.6109        0.478918                  415                  189\n",
      "101       8.59712       0.298822                  514                  239\n",
      "102       4.33663       0.393151                  332                   59\n",
      "103      15.2982        0.620567                  889                  451\n",
      "104       1.47243       0.147074                  200                   24\n",
      "105       2.27192       0.421041                  498                  149\n",
      "106       1.55022       0.448471                  356                   98\n",
      "107       4.77965       0.122628                  124                   51\n",
      "108       0.575914      0.369871                  463                   68\n",
      "109       4.0388        0.460747                  386                  152\n",
      "110      25.8219        0.161741                 1932                  596\n",
      "111      12.0316        0.470943                  895                  360\n",
      "112       3.84903       0.309038                  457                  129\n",
      "113      33.164         0.319238                  222                  100\n",
      "114       0.87729       0.218932                  173                   40\n",
      "115       8.76345       0.201408                  178                   28\n",
      "116       6.31751       0.31322                   596                  183\n",
      "117       1.24309       0.197161                  101                   27\n",
      "118      25.1427        0.111459                  711                  215\n",
      "119      16.5724        0.320813                  795                  296\n",
      "120       5.89975       0.266582                  459                  164\n",
      "121       4.31044       0.621488                 2646                  632\n",
      "122       0.474735      0.3297                    131                   26\n",
      "123      34.3287        0.282693                  885                  351\n",
      "124       1.63118       0.458781                  134                   51\n",
      "125       8.3217        0.302915                  373                  192\n",
      "126      19.5961        0.328389                 1290                  477\n",
      "127      10.176         0.204058                  556                  207\n",
      "128       7.59761       0.794638                 2019                  572\n",
      "129      18.4256        0.895797                   94                   81\n",
      "130      18.4876        0.619553                  319                  100\n",
      "131       0.642241      0.825267                  264                   77\n",
      "132       0.33476       0.673267                  162                   39\n",
      "133      12.692         0.346347                 1714                  723\n",
      "134       7.46916       0.369807                 1996                  388\n",
      "135      15.2352        0.259403                 3236                  741\n",
      "136      20.5293        0.265291                 1070                  459\n",
      "137       3.91327       0.310823                  107                   53\n",
      "138       7.84587       0.577879                 1139                  448\n",
      "139       2.71064       0.325497                  601                  236\n",
      "140      11.8597        0.478852                 1657                  632\n",
      "141      47.8279        0.352936                 7156                 2277\n",
      "142       3.48605       0.203008                  100                   39\n",
      "143      11.3202        0.429089                  752                  174\n",
      "144       9.65812       0.360395                 1073                  355\n",
      "145      78.0673        0.538396                21378                 6521\n",
      "146       1.2403        0.36591                    85                   44\n",
      "147       2.90707       0.866261                  832                  279\n",
      "148       3.54521       0.369329                  626                  191\n",
      "149       4.78301       0.418843                 1692                  544\n",
      "150      11.5972        0.422894                 1126                  406\n",
      "151       7.62613       0.238067                  415                   58\n",
      "152      15.6241        0.357716                 1138                  274\n",
      "153       6.34391       0.425685                  710                  248\n"
     ]
    }
   ],
   "source": [
    "headers = [\" \",\"Tweets Rate\",\"Mention Rate\", \"Unique Mentions\", \"Frequent Mentions\"]\n",
    "contents = []\n",
    "for i, timeSeries in enumerate(bd_clean):\n",
    "    tweets_rate = getTweetRate(timeSeries)\n",
    "    mention_rate = getMentioRate(timeSeries)\n",
    "    unique_mentions = getUniqueMentions(timeSeries)\n",
    "    frequent_mention = getFrequentMentions(timeSeries)\n",
    "    content = [i, tweets_rate, mention_rate, unique_mentions, frequent_mention]\n",
    "    contents.append(content)\n",
    "print(tabulate(contents, headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
