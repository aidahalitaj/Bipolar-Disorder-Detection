{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./library') # age_gender_predictor\n",
    "sys.path.append('../.env/lib/python2.7/site-packages') # make sure it can get virtualenv lib\n",
    "import age_gender_predictor\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "from nltk import PorterStemmer\n",
    "import re\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loding scikit-learn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_model(file_location):\n",
    "    model = joblib.load(file_location)\n",
    "    return model \n",
    "\n",
    "#Loding Bipolar Random Forest\n",
    "bipolar_model = load_model(\"models/bipolar_forest/bipolar_forest_0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data Function\n",
    "### Age and gender Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAgeGender(group):\n",
    "    features = {\"age\":[],\"gender\":[]}\n",
    "    for timeSeries in group:\n",
    "        \n",
    "        features[\"age\"].append(getAge(timeSeries))\n",
    "        features[\"gender\"].append(getGender(timeSeries))\n",
    "\n",
    "    return features\n",
    "def getAge(timeSeries):\n",
    "    texts = \"\"\n",
    "    for text in timeSeries[\"text\"].values:\n",
    "        texts += text + \"\\n\"\n",
    "    return age_gender_predictor.get_age(texts)\n",
    "\n",
    "def getGender(timeSeries):\n",
    "    texts = \"\"\n",
    "    for text in timeSeries[\"text\"].values:\n",
    "        texts += text + \"\\n\"\n",
    "    return age_gender_predictor.get_gender(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTweetRate(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    delta_time = np.max(timeSeries.index.values) - np.min(timeSeries.index.values)\n",
    "    total_duration = (delta_time).astype('timedelta64[h]') / np.timedelta64(24, 'h')\n",
    "    try:\n",
    "        result = total_tweets / float(total_duration)\n",
    "    except:\n",
    "        result = total_tweets / 1.0\n",
    "    return result\n",
    "\n",
    "def getLateTweetRate(timeSeries):\n",
    "    total_late = 0\n",
    "    for index in timeSeries.index:\n",
    "        if int(index.hour) <6:\n",
    "            total_late += 1\n",
    "    delta_time = np.max(timeSeries.index.values) - np.min(timeSeries.index.values)\n",
    "    total_duration = (delta_time).astype('timedelta64[h]') / np.timedelta64(24, 'h')\n",
    "    try:\n",
    "        result = total_late / float(total_duration)\n",
    "    except:\n",
    "        result = total_late / 1.0\n",
    "    return result\n",
    "\n",
    "def getMentionRate(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    total_mentions = np.sum(seriesContains(timeSeries))\n",
    "    return total_mentions / float(total_tweets)\n",
    "\n",
    "def thirdPronuonDetect(words, matcher=re.compile(\"@[a-z]+\")):\n",
    "    for word in words:\n",
    "        if word == \"@\":\n",
    "            continue\n",
    "        elif matcher.search(word):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def seriesContains(timeSeries):\n",
    "    match_function = np.vectorize(thirdPronuonDetect)\n",
    "    return match_function(timeSeries[\"text\"].str.lower().str.split().values)\n",
    "\n",
    "\n",
    "def getUniqueMentions(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    friends_set = set()\n",
    "    texts = timeSeries[\"text\"].values\n",
    "    for text in texts:\n",
    "        terms = text.strip().split()\n",
    "        for word in terms:\n",
    "            if word[0] == '@' and len(word) > 1:\n",
    "                friends_set.add(word)\n",
    "    return len(friends_set)\n",
    "\n",
    "def getFrequentMentions(timeSeries, lowerbound = 3):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    friends_mentions = {}\n",
    "    texts = timeSeries[\"text\"].values\n",
    "    for text in texts:\n",
    "        terms = text.strip().split()\n",
    "        for word in terms:\n",
    "            if word[0] == '@' and len(word) > 1:\n",
    "                friends_mentions[word] = friends_mentions.get(word, 0) +1\n",
    "    frequent_frients = [screen_name for screen_name, mentions in friends_mentions.items() if mentions >= lowerbound]\n",
    "    return len(frequent_frients)\n",
    " \n",
    "\n",
    "def getSocialFeature_group(group):\n",
    "    social_features = {\"tweets_rate\": [],\"mention_rate\": [],\"unique_mentions\": [],\"frequent_mentions\": [], \"late_tweets_rate\": []}\n",
    "    for timeSeries in group:\n",
    "        social_features[\"tweets_rate\"].append(getTweetRate(timeSeries))\n",
    "        social_features[\"mention_rate\"].append(getMentionRate(timeSeries))\n",
    "        social_features[\"unique_mentions\"].append(getUniqueMentions(timeSeries))\n",
    "        social_features[\"frequent_mentions\"].append(getFrequentMentions(timeSeries))\n",
    "        social_features[\"late_tweets_rate\"].append(getLateTweetRate(timeSeries))\n",
    "    return social_features\n",
    "\n",
    "def getAllFeature(group, tail_k = \"all\"):\n",
    "    feature_set = {}\n",
    "    methods = [getSocialFeature_group, getGroupEmotions, getPolarity, getAgeGender]\n",
    "    for method in methods:\n",
    "        feature_set.update(method(group.getGroup(tail_k)))\n",
    "    return feature_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFlipsCount(timeSeries, upperbound=120, lowerbound = 0):\n",
    "    flips = getFlips(timeSeries)\n",
    "    durations = getFlipsDuration(timeSeries, flips)\n",
    "    return np.sum((durations > lowerbound) & (durations < upperbound) )\n",
    "\n",
    "def getFlips(timeSeries, attribute= 'polarity'):\n",
    "    flips = np.zeros(timeSeries.shape[0],dtype=bool)\n",
    "    polarity = timeSeries[attribute].values[:-1]\n",
    "    right_elements = timeSeries[attribute].values[1:]\n",
    "    flips[:-1] = (polarity * right_elements) < 0\n",
    "    return flips\n",
    "\n",
    "def getFlipsDuration(timeSeries, flips):\n",
    "    filtered_timeSeries = timeSeries['dt'][flips].index.values\n",
    "    dt = np.zeros(filtered_timeSeries.shape[0],dtype=float)\n",
    "    dt[:-1] = (filtered_timeSeries[1:] - filtered_timeSeries[:-1]).astype('timedelta64[s]') / np.timedelta64(60, 's')\n",
    "    return dt\n",
    "\n",
    "def getCombosCount(timeSeries, matcher = -1, lowerbound = 2):\n",
    "    combos = comboTracker(timeSeries)\n",
    "    combos_count = sum([hit for element, hit in combos if element == matcher and hit > lowerbound])\n",
    "    return combos_count\n",
    "\n",
    "def getNegativeRatio(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    return np.sum(timeSeries[\"polarity\"].values == -1) / float(total_tweets)\n",
    "\n",
    "def getPositiveRatio(timeSeries):\n",
    "    total_tweets = timeSeries.shape[0]\n",
    "    return np.sum(timeSeries[\"polarity\"].values == 1) / float(total_tweets)\n",
    "\n",
    "def getPolarity(group):\n",
    "    polarity = {\"flips\":[],\"negative_combos\":[],\"positive_combos\":[], \"positive_ratio\":[], \"negative_ratio\":[]}\n",
    "    for timeSeries in group:\n",
    "        try:\n",
    "            tweets_length = float(timeSeries.shape[0])\n",
    "        except:\n",
    "            print 'error'\n",
    "            print timeSeries\n",
    "            break\n",
    "        flips_ratio = getFlipsCount(timeSeries) / tweets_length\n",
    "        negative_combos_ratio = getCombosCount(timeSeries,matcher=-1) / tweets_length\n",
    "        positive_combos_ratio = getCombosCount(timeSeries,matcher=1) / tweets_length\n",
    "        positive_ratio = getPositiveRatio(timeSeries)\n",
    "        negative_ratio = getNegativeRatio(timeSeries)\n",
    "        \n",
    "        polarity[\"flips\"].append(flips_ratio)\n",
    "        polarity[\"negative_combos\"].append(negative_combos_ratio)\n",
    "        polarity[\"positive_combos\"].append(positive_combos_ratio)\n",
    "        polarity[\"positive_ratio\"].append(positive_ratio)\n",
    "        polarity[\"negative_ratio\"].append(negative_ratio)\n",
    "        \n",
    "    return polarity\n",
    "\n",
    "def comboTracker(timeSeries, attribute= \"polarity\", lowerbound = 120):\n",
    "    array = timeSeries[attribute]\n",
    "#     the polarity of starter\n",
    "    starter = array[0]\n",
    "    combo = 1\n",
    "    result = []\n",
    "    i = 0 \n",
    "#     begin from second one in the array\n",
    "    for cursor in array[1:]:\n",
    "        i += 1\n",
    "        if starter == cursor and timeSeries[\"dt\"][i-1] < lowerbound:\n",
    "            combo += 1\n",
    "        else:\n",
    "            if combo > 1:\n",
    "                result.append((starter, combo))\n",
    "            starter = cursor\n",
    "            combo = 1\n",
    "    if combo > 1:\n",
    "         result.append((starter, combo))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_not_in_range(user, date):\n",
    "    if date >= patient_month_time_dict[user] - timedelta(days=42) \\\n",
    "    and date <= patient_month_time_dict[user] + timedelta(days=14):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def getUsersEmotionsDict(users_timeSeries):\n",
    "#     user -> emotion count\n",
    "    user_emotion_dict = defaultdict(lambda: {\"joy\":0,\n",
    "                                       \"sadness\": 0,\n",
    "                                       \"fear\":0,\n",
    "                                       \"anticipation\": 0,\n",
    "                                       \"anger\":0,\n",
    "                                       \"trust\": 0,\n",
    "                                       \"disgust\": 0,\n",
    "                                       \"surprise\" : 0\n",
    "                                      })\n",
    "    for user in users_timeSeries:\n",
    "        user_tweets_count = 0\n",
    "#         date, [tweet_info, tweets_info ...]\n",
    "        for date, tweets_infos in users_timeSeries[user].iteritems():\n",
    "            if date_not_in_range(user, datetime.strptime(str(date), \"%Y%m%d\")): continue\n",
    "            for tweet_info in tweets_infos:                \n",
    "    #             content, emotion1, emotion2, ambiguous\n",
    "                if(tweet_info[3].strip() != 'yes'):\n",
    "    #         only get the first emotion now\n",
    "                    user_emotion_dict[user][tweet_info[1]] += 1\n",
    "                    user_tweets_count += 1\n",
    "    \n",
    "        for emotion in user_emotion_dict[user]:\n",
    "            if user_tweets_count == 0:\n",
    "                user_emotion_dict[user][emotion] = 0\n",
    "            else:\n",
    "                user_emotion_dict[user][emotion] = float(user_emotion_dict[user][emotion]) / user_tweets_count\n",
    "    return user_emotion_dict\n",
    "\n",
    "def getUsersEmotions(timeSeries):\n",
    "    non_ambiguous = np.invert(timeSeries[\"ambiguous\"].values)\n",
    "    \n",
    "    filtered_emotions = timeSeries[\"emotion\"][non_ambiguous].values\n",
    "    emotions_count = {\"joy\":0,\"sadness\": 0,\"fear\":0,\\\n",
    "                \"anticipation\": 0, \"anger\":0, \"trust\": 0, \"disgust\": 0 ,\"surprise\" : 0}\n",
    "    if float(filtered_emotions.shape[0]) == 0:\n",
    "        divider = 1.0\n",
    "    else:\n",
    "        divider = float(filtered_emotions.shape[0])\n",
    "    for emotion in emotions_count:\n",
    "        emotions_count[emotion] = np.sum(filtered_emotions == emotion) / divider\n",
    "    return emotions_count\n",
    "\n",
    "def getGroupEmotions(group):\n",
    "    emotions_counts = {\"joy\":[],\"sadness\": [],\"fear\":[],\\\n",
    "                \"anticipation\": [], \"anger\":[], \"trust\": [], \"disgust\": [] ,\"surprise\" : []}\n",
    "    for timeSeries in group:\n",
    "        emotions_count = getUsersEmotions(timeSeries)\n",
    "        for emotion, count in emotions_count.items():\n",
    "            emotions_counts[emotion].append(count)\n",
    "    return emotions_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPOLFeature(user_timeSeries_list):\n",
    "    features = []\n",
    "    for timeSeries in user_timeSeries_list:\n",
    "        feature = np.zeros((len(group),11),dtype=float)\n",
    "        for i, timeSeries in enumerate(group):\n",
    "            tweets_length = timeSeries.shape[0]\n",
    "            tweets_rate = tweetRate(timeSeries)\n",
    "            mentio_rate = mentioRate(timeSeries)\n",
    "            unique_mentions = uniqueMentions(timeSeries)\n",
    "            frequent_mentions = frequentMentions(timeSeries)\n",
    "            negative_ratio = getNegativeRatio(timeSeries)\n",
    "            positive_ratio = getPositiveRatio(timeSeries)\n",
    "            flips_ratio = getFlipsCount(timeSeries) / tweets_length\n",
    "            negative_combos = getCombosCount(timeSeries) / tweets_length\n",
    "            positive_combos = getCombosCount(timeSeries,matcher=1) / tweets_length\n",
    "\n",
    "    \n",
    "            age = getAge(timeSeries)\n",
    "            gender = getGender(timeSeries)\n",
    "            \n",
    "            feature[i][0] = tweets_rate \n",
    "            feature[i][1] = mentio_rate\n",
    "            feature[i][2] = unique_mentions\n",
    "            feature[i][3] = frequent_mentions \n",
    "            feature[i][4] = positive_ratio\n",
    "            feature[i][5] = negative_ratio\n",
    "            feature[i][6] = flips_ratio\n",
    "            feature[i][7] = negative_combos\n",
    "            feature[i][8] = positive_combos\n",
    "            feature[i][9] = age\n",
    "            feature[i][10] = gender\n",
    "            \n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pol_report(tweets):\n",
    "#     A list of 8-weeks-timeSeries timeline\n",
    "    timeSeries_list = getTimeSeries(tweets)\n",
    "    features = getPOLFeature([timeSeries_list])\n",
    "    \n",
    "    user_timeline_reports = []\n",
    "    for feature in features:\n",
    "        feature = features[0]\n",
    "        timeSeries = timeSeries_list[0]\n",
    "        bipolar_proba = bipolar_model.predict_proba(features)[0][1]\n",
    "        BPD_proba = BPD_model.predict_proba(features)[0][1]\n",
    "\n",
    "        report = {}\n",
    "        report[\"tweets_length\"] = len(tweets)\n",
    "        report[\"tweeting_frequency\"] = feature[0]\n",
    "        report[\"mentioning_frequency\"] = feature[1]\n",
    "        report[\"unique_mentioning\"] = feature[2]\n",
    "        report[\"frequent_mentioning\"] = feature[3]\n",
    "        report[\"positive_ratio\"] = feature[4]\n",
    "        report[\"negative_ratio\"] = feature[5]\n",
    "        report[\"flips_ratio\"] = feature[6]\n",
    "        report[\"negative_combos\"] = feature[7]\n",
    "        report[\"positive_combos\"] = feature[8]\n",
    "        report[\"age\"] = features[0][9]\n",
    "        report[\"gender\"] = \"Male\" if features[0][10] < 0 else \"Female\"\n",
    "        report[\"bipolar_probability\"] = bipolar_proba\n",
    "        report[\"BPD_probability\"] = BPD_proba\n",
    "        report[\"flip_tweets\"] = getFlipsTweets(timeSeries)\n",
    "        report[\"combo_tweets\"] = getCombosTweets(timeSeries)\n",
    "        report[\"negative_tweets\"] = getLabeledTweets(timeSeries, label=-1, k=40)\n",
    "        report[\"positive_tweets\"] = getLabeledTweets(timeSeries, label = 1, k=40)\n",
    "        report[\"latest_tweets\"] = getLabeledTweets(timeSeries, k=300)\n",
    "        \n",
    "        user_timeline_reports.append(report)\n",
    "\n",
    "    return user_timeline_reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
